node {
  name: "tensor_12_odule/model/61/up_proj/placeholder/1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INVALID
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 7168
        }
        dim {
          size: 8192
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "hfloat8"
    }
  }
}
node {
  name: "module/model/61/up_proj/fp8_gemm_bf16/15818_complex/fp8_gemm_bf16_3551/expand_dims_6"
  op: "ExpandDims"
  input: "tensor_12_odule/model/61/up_proj/placeholder/1"
  attr {
    key: "Bundle_idx"
    value {
      s: "N/A"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "0"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "N/A"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_12_odule/model/61/up_proj/placeholder/1  |  Sizes = [8192,7168]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 7168, 1]  |  data = 0, sizeInBytes = 58720256  |  isPersistent  |  location = in DRAM  |  dramOffset = 0x80000000000  |  userMemorySection(type=Persistent, id=8)  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "hf8-7_237100  |  Sizes = [1,8192,7168]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 58720256, 7168, 1]  |  data = 0, sizeInBytes = 58720256  |  isAliased = tensor_12_odule/model/61/up_proj/placeholder/1, type = alias, offset: 0  |  location = in DRAM  |  "
    }
  }
}
node {
  name: "tensor_21_odule/model/61/gate_proj/placeholder/1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INVALID
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 7168
        }
        dim {
          size: 8192
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "hfloat8"
    }
  }
}
node {
  name: "module/model/61/gate_proj/fp8_gemm_bf16/15820_complex/fp8_gemm_bf16_3553/expand_dims_6"
  op: "ExpandDims"
  input: "tensor_21_odule/model/61/gate_proj/placeholder/1"
  attr {
    key: "Bundle_idx"
    value {
      s: "N/A"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "1"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "N/A"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_21_odule/model/61/gate_proj/placeholder/1  |  Sizes = [8192,7168]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 7168, 1]  |  data = 0, sizeInBytes = 58720256  |  isPersistent  |  location = in DRAM  |  dramOffset = 0xc0000000000  |  userMemorySection(type=Persistent, id=12)  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "hf8-7_237104  |  Sizes = [1,8192,7168]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 58720256, 7168, 1]  |  data = 0, sizeInBytes = 58720256  |  isAliased = tensor_21_odule/model/61/gate_proj/placeholder/1, type = alias, offset: 0  |  location = in DRAM  |  "
    }
  }
}
node {
  name: "tensor_0_odule/model/61/placeholder/0"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_BFLOAT16
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8192
        }
        dim {
          size: 128
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "bf16"
    }
  }
}
node {
  name: "tensor_1_odule/model/61/placeholder/1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_BFLOAT16
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8192
        }
        dim {
          size: 128
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "bf16"
    }
  }
}
node {
  name: "module/model/61/add_fwd_bf16/15815_complex/add_fwd_bf16_0_bundle_1332/op_0"
  op: "add_fwd_bf16"
  input: "tensor_0_odule/model/61/placeholder/0"
  input: "tensor_1_odule/model/61/placeholder/1"
  attr {
    key: "Bundle_idx"
    value {
      s: "1332"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "2"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "0"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_0_odule/model/61/placeholder/0  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  isPersistent  |  location = in DRAM  |  dramOffset = 0x40000000000  |  userMemorySection(type=Persistent, id=4)  |  "
    }
  }
  attr {
    key: "inputTensor:1"
    value {
      s: "tensor_1_odule/model/61/placeholder/1  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  isPersistent  |  location = in DRAM  |  dramOffset = 0x50000000000  |  userMemorySection(type=Persistent, id=5)  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "tensor_2_slice_0_0_0_0_0__0__bundle_1332_237306  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  location = in SRAM  |  sramOffset = 0x1000fffffd050000  |  "
    }
  }
}
node {
  name: "module/model/61/post_attention_layernorm/rms_norm_ex_fwd_bf16/15816_complex/rms_norm_ex_fwd_bf16_891/reshape_4_bundle_1332/op_1"
  op: "Reshape"
  input: "module/model/61/add_fwd_bf16/15815_complex/add_fwd_bf16_0_bundle_1332/op_0"
  attr {
    key: "Bundle_idx"
    value {
      s: "1332"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "3"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "1"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_2_slice_0_0_0_0_0__0__bundle_1332_237306  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  location = in SRAM  |  sramOffset = 0x1000fffffd050000  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "bf16-5_237094_slice_0_0_0_0_0__0__bundle_1332_237307  |  Sizes = [128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  isAliased = tensor_2_slice_0_0_0_0_0__0__bundle_1332_237306, type = alias, offset: 0  |  location = in SRAM  |  sramOffset = 0x1000fffffd050000  |  "
    }
  }
}
node {
  name: "tensor_3_odule/model/61/post_attention_layernorm/placeholder/1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_BFLOAT16
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8192
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "bf16"
    }
  }
}
node {
  name: "module/model/61/post_attention_layernorm/rms_norm_ex_fwd_bf16/15816_complex/rms_norm_ex_fwd_bf16_891/rms_norm_fwd_bf16_6_bundle_1332/op_2"
  op: "rms_norm_fwd_bf16"
  input: "module/model/61/post_attention_layernorm/rms_norm_ex_fwd_bf16/15816_complex/rms_norm_ex_fwd_bf16_891/reshape_4_bundle_1332/op_1"
  input: "tensor_3_odule/model/61/post_attention_layernorm/placeholder/1"
  attr {
    key: "Bundle_idx"
    value {
      s: "1332"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "4"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "2"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "bf16-5_237094_slice_0_0_0_0_0__0__bundle_1332_237307  |  Sizes = [128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  isAliased = tensor_2_slice_0_0_0_0_0__0__bundle_1332_237306, type = alias, offset: 0  |  location = in SRAM  |  sramOffset = 0x1000fffffd050000  |  "
    }
  }
  attr {
    key: "inputTensor:1"
    value {
      s: "tensor_3_odule/model/61/post_attention_layernorm/placeholder/1  |  Sizes = [8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [16384, 2]  |  data = 0, sizeInBytes = 16384  |  isPersistent  |  location = in DRAM  |  dramOffset = 0x60000000000  |  userMemorySection(type=Persistent, id=6)  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "bf16-7_237095_slice_0_0_0_0_0__0__bundle_1332_237309  |  Sizes = [128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  isAliased = tensor-237284_slice_0_0_0_0_0__0__bundle_1332_237311, type = alias, offset: 0  |  location = in SRAM  |  sramOffset = 0x1000fffffd250000  |  "
    }
  }
  attr {
    key: "outputTensor:1"
    value {
      s: "f32-8_237096  |  Sizes = [128,1]  |  float32  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [512, 4, 4]  |  data = 0, sizeInBytes = 512  |  location = in DRAM  |  dramOffset = 0x140000000000  |  "
    }
  }
}
node {
  name: "f32-8_237096"
  op: "OutputTensor"
  input: "module/model/61/post_attention_layernorm/rms_norm_ex_fwd_bf16/15816_complex/rms_norm_ex_fwd_bf16_891/rms_norm_fwd_bf16_6_bundle_1332/op_2"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 1
        }
        dim {
          size: 128
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "float32"
    }
  }
}
node {
  name: "reshape_0_0_bundle_1332/op_3"
  op: "Reshape"
  input: "module/model/61/post_attention_layernorm/rms_norm_ex_fwd_bf16/15816_complex/rms_norm_ex_fwd_bf16_891/rms_norm_fwd_bf16_6_bundle_1332/op_2"
  attr {
    key: "Bundle_idx"
    value {
      s: "1332"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "5"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "3"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "bf16-7_237095_slice_0_0_0_0_0__0__bundle_1332_237309  |  Sizes = [128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  isAliased = tensor-237284_slice_0_0_0_0_0__0__bundle_1332_237311, type = alias, offset: 0  |  location = in SRAM  |  sramOffset = 0x1000fffffd250000  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "tensor-237284_slice_0_0_0_0_0__0__bundle_1332_237311  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  location = in SRAM  |  sramOffset = 0x1000fffffd250000  |  "
    }
  }
}
node {
  name: "fusedTPCNode_469_0_bundle_1332/op_4"
  op: "fused_kernel_0xF762EE51_54C_hf8"
  input: "reshape_0_0_bundle_1332/op_3"
  attr {
    key: "Bundle_idx"
    value {
      s: "1332"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "6"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "4"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor-237284_slice_0_0_0_0_0__0__bundle_1332_237311  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  location = in SRAM  |  sramOffset = 0x1000fffffd250000  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "tensor_11_slice_0_0_0_0_0__0__bundle_1332_237312  |  Sizes = [1,128,8192]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [1048576, 1048576, 8192, 1]  |  data = 0, sizeInBytes = 1048576  |  location = in SRAM  |  sramOffset = 0x1000fffffd450000  |  "
    }
  }
}
node {
  name: "module/model/61/up_proj/fp8_gemm_bf16/15818_complex/fp8_gemm_bf16_3551/batch_gemm_8_bundle_1332/op_5_gemm"
  op: "GEMM"
  input: "fusedTPCNode_469_0_bundle_1332/op_4"
  input: "module/model/61/up_proj/fp8_gemm_bf16/15818_complex/fp8_gemm_bf16_3551/expand_dims_6"
  attr {
    key: "Bundle_idx"
    value {
      s: "1332"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "7"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "5"
    }
  }
  attr {
    key: "Parameters"
    value {
      s: "transpose_a=false, transpose_b=false"
    }
  }
  attr {
    key: "fp8BiasIn"
    value {
      s: "7"
    }
  }
  attr {
    key: "fp8BiasIn2"
    value {
      s: "15"
    }
  }
  attr {
    key: "fp8BiasOut"
    value {
      s: "0"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_11_slice_0_0_0_0_0__0__bundle_1332_237312  |  Sizes = [1,128,8192]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [1048576, 1048576, 8192, 1]  |  data = 0, sizeInBytes = 1048576  |  location = in SRAM  |  sramOffset = 0x1000fffffd450000  |  "
    }
  }
  attr {
    key: "inputTensor:1"
    value {
      s: "hf8-7_237100  |  Sizes = [1,8192,7168]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 58720256, 7168, 1]  |  data = 0, sizeInBytes = 58720256  |  isAliased = tensor_12_odule/model/61/up_proj/placeholder/1, type = alias, offset: 0  |  location = in DRAM  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "tensor_16  |  Sizes = [1,128,7168]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [1835008, 1835008, 14336, 2]  |  data = 0, sizeInBytes = 1835008  |  location = in DRAM  |  dramOffset = 0x140000000200  |  "
    }
  }
}
node {
  name: "module/model/61/gate_proj/fp8_gemm_bf16/15820_complex/fp8_gemm_bf16_3553/batch_gemm_8_bundle_1332/op_6_gemm"
  op: "GEMM"
  input: "fusedTPCNode_469_0_bundle_1332/op_4"
  input: "module/model/61/gate_proj/fp8_gemm_bf16/15820_complex/fp8_gemm_bf16_3553/expand_dims_6"
  attr {
    key: "Bundle_idx"
    value {
      s: "1332"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "8"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "6"
    }
  }
  attr {
    key: "Parameters"
    value {
      s: "transpose_a=false, transpose_b=false"
    }
  }
  attr {
    key: "fp8BiasIn"
    value {
      s: "7"
    }
  }
  attr {
    key: "fp8BiasIn2"
    value {
      s: "15"
    }
  }
  attr {
    key: "fp8BiasOut"
    value {
      s: "0"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_11_slice_0_0_0_0_0__0__bundle_1332_237312  |  Sizes = [1,128,8192]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [1048576, 1048576, 8192, 1]  |  data = 0, sizeInBytes = 1048576  |  location = in SRAM  |  sramOffset = 0x1000fffffd450000  |  "
    }
  }
  attr {
    key: "inputTensor:1"
    value {
      s: "hf8-7_237104  |  Sizes = [1,8192,7168]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 58720256, 7168, 1]  |  data = 0, sizeInBytes = 58720256  |  isAliased = tensor_21_odule/model/61/gate_proj/placeholder/1, type = alias, offset: 0  |  location = in DRAM  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "tensor_25  |  Sizes = [1,128,7168]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [1835008, 1835008, 14336, 2]  |  data = 0, sizeInBytes = 1835008  |  location = in DRAM  |  dramOffset = 0x0  |  "
    }
  }
}
node {
  name: "tensor_2_bundle_1332/memcpy/0"
  op: "DmaMemcpy"
  input: "module/model/61/add_fwd_bf16/15815_complex/add_fwd_bf16_0_bundle_1332/op_0"
  input: "^module/model/61/add_fwd_bf16/15815_complex/add_fwd_bf16_0_bundle_1332/op_0"
  attr {
    key: "Bundle_idx"
    value {
      s: "1332"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "9"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "7"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_2_slice_0_0_0_0_0__0__bundle_1332_237306  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  location = in SRAM  |  sramOffset = 0x1000fffffd050000  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "tensor_2  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  isPersistent  |  location = in DRAM  |  dramOffset = 0x40000000000  |  userMemorySection(type=Persistent, id=4)  |  "
    }
  }
}
node {
  name: "tensor_2"
  op: "OutputTensor"
  input: "tensor_2_bundle_1332/memcpy/0"
  attr {
    key: "dtype"
    value {
      type: DT_BFLOAT16
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8192
        }
        dim {
          size: 128
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "bf16"
    }
  }
}
node {
  name: "tensor_32_odule/model/61/down_proj/placeholder/1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INVALID
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8192
        }
        dim {
          size: 7168
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "hfloat8"
    }
  }
}
node {
  name: "module/model/61/down_proj/fp8_gemm_bf16/15824_complex/fp8_gemm_bf16_3555/expand_dims_6"
  op: "ExpandDims"
  input: "tensor_32_odule/model/61/down_proj/placeholder/1"
  attr {
    key: "Bundle_idx"
    value {
      s: "N/A"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "10"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "N/A"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_32_odule/model/61/down_proj/placeholder/1  |  Sizes = [7168,8192]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 8192, 1]  |  data = 0, sizeInBytes = 58720256  |  isPersistent  |  location = in DRAM  |  dramOffset = 0x100000000000  |  userMemorySection(type=Persistent, id=16)  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "hf8-7_237112  |  Sizes = [1,7168,8192]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 58720256, 8192, 1]  |  data = 0, sizeInBytes = 58720256  |  isAliased = tensor_32_odule/model/61/down_proj/placeholder/1, type = alias, offset: 0  |  location = in DRAM  |  "
    }
  }
}
node {
  name: "fusedTPCNode_469_1_bundle_1333/op_0"
  op: "fused_kernel_0xA6E0A64C_54D_bf16"
  input: "module/model/61/gate_proj/fp8_gemm_bf16/15820_complex/fp8_gemm_bf16_3553/batch_gemm_8_bundle_1332/op_6_gemm"
  input: "module/model/61/up_proj/fp8_gemm_bf16/15818_complex/fp8_gemm_bf16_3551/batch_gemm_8_bundle_1332/op_5_gemm"
  attr {
    key: "Bundle_idx"
    value {
      s: "1333"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "11"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "0"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_25  |  Sizes = [1,128,7168]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [1835008, 1835008, 14336, 2]  |  data = 0, sizeInBytes = 1835008  |  location = in DRAM  |  dramOffset = 0x0  |  "
    }
  }
  attr {
    key: "inputTensor:1"
    value {
      s: "tensor_16  |  Sizes = [1,128,7168]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [1835008, 1835008, 14336, 2]  |  data = 0, sizeInBytes = 1835008  |  location = in DRAM  |  dramOffset = 0x140000000200  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "tensor_31_slice_0_0_0_0_0__0__bundle_1333_237322  |  Sizes = [1,128,7168]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [917504, 917504, 7168, 1]  |  data = 0, sizeInBytes = 917504  |  location = in SRAM  |  sramOffset = 0x1000fffffd550000  |  "
    }
  }
}
node {
  name: "module/model/61/down_proj/fp8_gemm_bf16/15824_complex/fp8_gemm_bf16_3555/batch_gemm_8_bundle_1333/op_1_gemm"
  op: "GEMM"
  input: "fusedTPCNode_469_1_bundle_1333/op_0"
  input: "module/model/61/down_proj/fp8_gemm_bf16/15824_complex/fp8_gemm_bf16_3555/expand_dims_6"
  attr {
    key: "Bundle_idx"
    value {
      s: "1333"
    }
  }
  attr {
    key: "Exec_idx"
    value {
      s: "12"
    }
  }
  attr {
    key: "Op_idx"
    value {
      s: "1"
    }
  }
  attr {
    key: "Parameters"
    value {
      s: "transpose_a=false, transpose_b=false"
    }
  }
  attr {
    key: "fp8BiasIn"
    value {
      s: "7"
    }
  }
  attr {
    key: "fp8BiasIn2"
    value {
      s: "15"
    }
  }
  attr {
    key: "fp8BiasOut"
    value {
      s: "0"
    }
  }
  attr {
    key: "inputTensor:0"
    value {
      s: "tensor_31_slice_0_0_0_0_0__0__bundle_1333_237322  |  Sizes = [1,128,7168]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [917504, 917504, 7168, 1]  |  data = 0, sizeInBytes = 917504  |  location = in SRAM  |  sramOffset = 0x1000fffffd550000  |  "
    }
  }
  attr {
    key: "inputTensor:1"
    value {
      s: "hf8-7_237112  |  Sizes = [1,7168,8192]  |  hfloat8  |  expBias = 7, scale = 1  |    |  ModelParam = 0  |  strides = [58720256, 58720256, 8192, 1]  |  data = 0, sizeInBytes = 58720256  |  isAliased = tensor_32_odule/model/61/down_proj/placeholder/1, type = alias, offset: 0  |  location = in DRAM  |  "
    }
  }
  attr {
    key: "outputTensor:0"
    value {
      s: "tensor_36  |  Sizes = [1,128,8192]  |  bf16  |  expBias = 0, scale = 1  |    |  ModelParam = 0  |  strides = [2097152, 2097152, 16384, 2]  |  data = 0, sizeInBytes = 2097152  |  isPersistent  |  location = in DRAM  |  dramOffset = 0x140000000000  |  userMemorySection(type=Persistent, id=20)  |  "
    }
  }
}
node {
  name: "tensor_36"
  op: "OutputTensor"
  input: "module/model/61/down_proj/fp8_gemm_bf16/15824_complex/fp8_gemm_bf16_3555/batch_gemm_8_bundle_1333/op_1_gemm"
  attr {
    key: "dtype"
    value {
      type: DT_BFLOAT16
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8192
        }
        dim {
          size: 128
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "synDataType"
    value {
      s: "bf16"
    }
  }
}
